{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "da-playground-2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mwclient"
      ],
      "metadata": {
        "id": "M7VefSKl5yLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import difflib\n",
        "import matplotlib.pyplot as plt\n",
        "import mwclient\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "X_v1eMro5HaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Donwload VADER but what is VADER?\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "DKQBwl545LCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a wiki revision exttraction function\n",
        "def fetch_wikipedia_revisions(page_title, limit=10):\n",
        "    site = mwclient.Site('en.wikipedia.org')\n",
        "    page = site.pages[page_title]\n",
        "\n",
        "    # Fetch revisions\n",
        "    revisions = []\n",
        "    for rev in page.revisions(prop='content|timestamp', limit=limit):\n",
        "        print(\"Fetched revision\", rev)\n",
        "        revisions.append(rev)\n",
        "    return revisions\n"
      ],
      "metadata": {
        "id": "ckLnF0Kt5M4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing revisions\n",
        "def compare_revisions(rev1, rev2):\n",
        "    diff = difflib.unified_diff(rev1.splitlines(), rev2.splitlines(), lineterm='')\n",
        "    change_text = '\\n'.join(diff)\n",
        "    return change_text\n"
      ],
      "metadata": {
        "id": "XJ-Lx6Ja5N4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return sentiment\n",
        "def sentiment_analysis(text):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    sentiment = sia.polarity_scores(text)\n",
        "    return sentiment\n"
      ],
      "metadata": {
        "id": "AgzWkEKT5OhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a fancy plot...\n",
        "def plot_sentiment_evolution(timestamps, sentiments, window=3, frac=0.3):\n",
        "    # Extract compound scores for sentiment evolution\n",
        "    compound_scores = [s['compound'] for s in sentiments]\n",
        "    # Convert timestamps to datetime objects directly\n",
        "    dates = [datetime.datetime(*ts[:6]) for ts in timestamps]\n",
        "    # Create a DataFrame for rolling average calculation\n",
        "    df = pd.DataFrame({'date': dates, 'compound_score': compound_scores})\n",
        "    df.set_index('date', inplace=True)\n",
        "    # Calculate rolling average\n",
        "    df['rolling_avg'] = df['compound_score'].rolling(window=window, min_periods=1).mean()\n",
        "    # Apply Lowess smoothing\n",
        "    smoothed = lowess(df['compound_score'], df.index, frac=frac, it=0, return_sorted=False)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    # Plot rolling average\n",
        "    plt.plot(df.index, df['rolling_avg'], marker='h', linestyle='-', linewidth=2, label=f'{window}-Period Rolling Average', alpha=.5)\n",
        "    # Plot smoothed line\n",
        "    plt.plot(df.index, smoothed, linestyle='-', linewidth=4, label='Lowess Smoothed')\n",
        "    plt.title('Sentiment of Wikipedia Page Changes', fontsize=20)\n",
        "    plt.xlabel('Date', fontsize=16)\n",
        "    plt.ylabel('Sentiment Score', fontsize=16)\n",
        "    plt.grid(True)\n",
        "    plt.xticks(rotation=45, fontsize=12)\n",
        "    plt.yticks(fontsize=12)\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pdOh4qCX5PCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_title = 'Gabriel Attal'\n",
        "revisions = fetch_wikipedia_revisions(page_title)\n",
        "\n",
        "timestamps = []\n",
        "sentiments = []"
      ],
      "metadata": {
        "id": "a0MJ20pk5RFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(revisions) - 1):\n",
        "    print(\"Starting \", i, \"out of\", len(revisions))\n",
        "    rev1 = revisions[i]['*']\n",
        "    rev2 = revisions[i + 1]['*']\n",
        "\n",
        "    changes = compare_revisions(rev1, rev2)\n",
        "    sentiment = sentiment_analysis(changes)\n",
        "\n",
        "    timestamps.append(revisions[i]['timestamp'])\n",
        "    sentiments.append(sentiment)"
      ],
      "metadata": {
        "id": "Y-Mk80Nh5SIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sentiment_evolution(timestamps, sentiments, window=15, frac=0.5)"
      ],
      "metadata": {
        "id": "Et4OnOgC5Thj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
